{"created": 1760103663.574416, "duration": 156.23453497886658, "exitcode": 1, "root": "/Users/finnvonheesen/Desktop/quote-builder-llm-benchmark", "environment": {}, "summary": {"passed": 9, "failed": 2, "total": 11, "collected": 11}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/test_auth_api.py", "type": "Module"}]}, {"nodeid": "tests/test_auth_api.py", "outcome": "passed", "result": [{"nodeid": "tests/test_auth_api.py::test_happy_path_signup_login_me", "type": "Function", "lineno": 25}, {"nodeid": "tests/test_auth_api.py::test_duplicate_signup_returns_409", "type": "Function", "lineno": 35}, {"nodeid": "tests/test_auth_api.py::test_login_wrong_password_401", "type": "Function", "lineno": 41}, {"nodeid": "tests/test_auth_api.py::test_me_requires_bearer_token", "type": "Function", "lineno": 46}, {"nodeid": "tests/test_auth_api.py::test_token_expiry_short_lifetime", "type": "Function", "lineno": 51}, {"nodeid": "tests/test_auth_api.py::test_property_valid_inputs_pass_signup_then_login", "type": "Function", "lineno": 60}, {"nodeid": "tests/test_auth_api.py::test_password_policy_enforced", "type": "Function", "lineno": 73}, {"nodeid": "tests/test_auth_api.py::test_email_policy_enforced", "type": "Function", "lineno": 78}, {"nodeid": "tests/test_auth_api.py::test_error_messages_do_not_leak", "type": "Function", "lineno": 82}, {"nodeid": "tests/test_auth_api.py::test_sql_injection_defense", "type": "Function", "lineno": 88}, {"nodeid": "tests/test_auth_api.py::test_dependencies_are_minimal_and_no_debug_headers", "type": "Function", "lineno": 94}]}], "tests": [{"nodeid": "tests/test_auth_api.py::test_happy_path_signup_login_me", "lineno": 25, "outcome": "passed", "keywords": ["test_happy_path_signup_login_me", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.04705295899475459, "outcome": "passed"}, "call": {"duration": 0.32824399998935405, "outcome": "passed"}, "teardown": {"duration": 0.0002541249996284023, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_duplicate_signup_returns_409", "lineno": 35, "outcome": "passed", "keywords": ["test_duplicate_signup_returns_409", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0016734170058043674, "outcome": "passed"}, "call": {"duration": 0.3334430000104476, "outcome": "passed"}, "teardown": {"duration": 0.00022066700330469757, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_login_wrong_password_401", "lineno": 41, "outcome": "passed", "keywords": ["test_login_wrong_password_401", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0016513330047018826, "outcome": "passed"}, "call": {"duration": 0.32770683300623205, "outcome": "passed"}, "teardown": {"duration": 0.00019691699708346277, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_me_requires_bearer_token", "lineno": 46, "outcome": "passed", "keywords": ["test_me_requires_bearer_token", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0016704589943401515, "outcome": "passed"}, "call": {"duration": 0.00039387498691212386, "outcome": "passed"}, "teardown": {"duration": 0.0001459580089431256, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_token_expiry_short_lifetime", "lineno": 51, "outcome": "passed", "keywords": ["test_token_expiry_short_lifetime", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0012198329932289198, "outcome": "passed"}, "call": {"duration": 0.00022583299141842872, "outcome": "passed"}, "teardown": {"duration": 0.00014562500291503966, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_property_valid_inputs_pass_signup_then_login", "lineno": 60, "outcome": "failed", "keywords": ["test_property_valid_inputs_pass_signup_then_login", "is_hypothesis_test", "_hypothesis_internal_use_seed", "_hypothesis_internal_use_settings", "_hypothesis_internal_use_reproduce_failure", "hypothesis", "_hypothesis_internal_settings_applied", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0011161669972352684, "outcome": "passed"}, "call": {"duration": 154.54703783299192, "outcome": "failed", "crash": {"path": "/Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/hypothesis/internal/conjecture/datatree.py", "lineno": 1124, "message": "hypothesis.errors.FlakyReplay: Inconsistent results from replaying a test case!\n  last: INTERESTING from Failed at /Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/_pytest/outcomes.py:178\n  this: INTERESTING from DeadlineExceeded at /Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/hypothesis/core.py:877"}, "traceback": [{"path": "tests/test_auth_api.py", "lineno": 62, "message": ""}, {"path": "venv/lib/python3.13/site-packages/hypothesis/internal/conjecture/datatree.py", "lineno": 1124, "message": "FlakyReplay"}], "longrepr": "client = <FlaskClient <Flask 'candidate_app'>>, email = 'Mx@Mv1.BAB', pwd = '0000000A'\n\n    @settings(suppress_health_check=[HealthCheck.function_scoped_fixture], max_examples=30)\n>   @given(email=EMAILS, pwd=PASSWORDS_VALID)\n\ntests/test_auth_api.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (<FlaskClient <Flask 'candidate_app'>>, 'Mx@Mv1.BAB', '0000000A'), kwargs = {}, arg_drawtime = 0.0005799589998787269, arg_stateful = 0.0, arg_gctime = 0.2590161360130878\nstart = 73713.709863041, result = None, finish = 73714.031910208, in_drawtime = 0.0, in_stateful = 0.0, in_gctime = 0.0, runtime = 0.3220471669919789\n\n    @proxies(self.test)\n    def test(*args, **kwargs):\n        arg_drawtime = math.fsum(data.draw_times.values())\n        arg_stateful = math.fsum(data._stateful_run_times.values())\n        arg_gctime = gc_cumulative_time()\n        start = time.perf_counter()\n        try:\n            with ensure_free_stackframes():\n                result = self.test(*args, **kwargs)\n        finally:\n            finish = time.perf_counter()\n            in_drawtime = math.fsum(data.draw_times.values()) - arg_drawtime\n            in_stateful = (\n                math.fsum(data._stateful_run_times.values()) - arg_stateful\n            )\n            in_gctime = gc_cumulative_time() - arg_gctime\n            runtime = finish - start - in_drawtime - in_stateful - in_gctime\n            self._timing_features = {\n                \"execute:test\": runtime,\n                \"overall:gc\": in_gctime,\n                **data.draw_times,\n                **data._stateful_run_times,\n            }\n    \n        if (current_deadline := self.settings.deadline) is not None:\n            if not is_final:\n                current_deadline = (current_deadline // 4) * 5\n            if runtime >= current_deadline.total_seconds():\n>               raise DeadlineExceeded(\n                    datetime.timedelta(seconds=runtime), self.settings.deadline\n                )\nE               hypothesis.errors.DeadlineExceeded: Test took 322.05ms, which exceeds the deadline of 200.00ms\n\nvenv/lib/python3.13/site-packages/hypothesis/core.py:877: DeadlineExceeded\n\nDuring handling of the above exception, another exception occurred:\n\nclient = <FlaskClient <Flask 'candidate_app'>>\n\n    @settings(suppress_health_check=[HealthCheck.function_scoped_fixture], max_examples=30)\n>   @given(email=EMAILS, pwd=PASSWORDS_VALID)\n\ntests/test_auth_api.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <hypothesis.internal.conjecture.datatree.TreeRecordingObserver object at 0x113ee81a0>, status = Status.INTERESTING\ninteresting_origin = InterestingOrigin(exc_type=<class 'hypothesis.errors.DeadlineExceeded'>, filename='/Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/hypothesis/core.py', lineno=877, context=(), group_elems=())\n\n    def conclude_test(self, status, interesting_origin):\n        \"\"\"Says that ``status`` occurred at node ``node``. This updates the\n        node if necessary and checks for consistency.\"\"\"\n        if status == Status.OVERRUN:\n            return\n        i = self.__index_in_current_node\n        node = self.__current_node\n    \n        if i < len(node.values) or isinstance(node.transition, Branch):\n            inconsistent_generation()\n    \n        new_transition = Conclusion(status, interesting_origin)\n    \n        if node.transition is not None and node.transition != new_transition:\n            # As an, I'm afraid, horrible bodge, we deliberately ignore flakiness\n            # where tests go from interesting to valid, because it's much easier\n            # to produce good error messages for these further up the stack.\n            if isinstance(node.transition, Conclusion) and (\n                node.transition.status != Status.INTERESTING\n                or new_transition.status != Status.VALID\n            ):\n                old_origin = node.transition.interesting_origin\n                new_origin = new_transition.interesting_origin\n>               raise FlakyReplay(\n                    f\"Inconsistent results from replaying a test case!\\n\"\n                    f\"  last: {node.transition.status.name} from {old_origin}\\n\"\n                    f\"  this: {new_transition.status.name} from {new_origin}\",\n                    (old_origin, new_origin),\n                )\nE               hypothesis.errors.FlakyReplay: Inconsistent results from replaying a test case!\nE                 last: INTERESTING from Failed at /Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/_pytest/outcomes.py:178\nE                 this: INTERESTING from DeadlineExceeded at /Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/venv/lib/python3.13/site-packages/hypothesis/core.py:877\n\nvenv/lib/python3.13/site-packages/hypothesis/internal/conjecture/datatree.py:1124: FlakyReplay"}, "teardown": {"duration": 0.00040004200127441436, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_password_policy_enforced", "lineno": 73, "outcome": "passed", "keywords": ["test_password_policy_enforced", "is_hypothesis_test", "_hypothesis_internal_use_seed", "_hypothesis_internal_use_settings", "_hypothesis_internal_use_reproduce_failure", "hypothesis", "_hypothesis_internal_settings_applied", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0018038339912891388, "outcome": "passed"}, "call": {"duration": 0.05203312500088941, "outcome": "passed"}, "teardown": {"duration": 0.00024958398716989905, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_email_policy_enforced", "lineno": 78, "outcome": "failed", "keywords": ["test_email_policy_enforced", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0015632080030627549, "outcome": "passed"}, "call": {"duration": 0.16429591600899585, "outcome": "failed", "crash": {"path": "/Users/finnvonheesen/Desktop/quote-builder-llm-benchmark/tests/test_auth_api.py", "lineno": 81, "message": "AssertionError: assert 201 == 400\n +  where 201 = <WrapperTestResponse streamed [201 CREATED]>.status_code\n +    where <WrapperTestResponse streamed [201 CREATED]> = signup(<FlaskClient <Flask 'candidate_app'>>, 'a@b.c', 'Strong123')"}, "traceback": [{"path": "tests/test_auth_api.py", "lineno": 81, "message": "AssertionError"}], "longrepr": "client = <FlaskClient <Flask 'candidate_app'>>\n\n    def test_email_policy_enforced(client):\n        for bad in [\"x\", \"user@\", \"@domain.com\", \"a@b\", \"a@b.\", \"a@b.c\", \"a@b..com\", \"a b@c.com\"]:\n>           assert signup(client, bad, \"Strong123\").status_code == 400\nE           AssertionError: assert 201 == 400\nE            +  where 201 = <WrapperTestResponse streamed [201 CREATED]>.status_code\nE            +    where <WrapperTestResponse streamed [201 CREATED]> = signup(<FlaskClient <Flask 'candidate_app'>>, 'a@b.c', 'Strong123')\n\ntests/test_auth_api.py:81: AssertionError"}, "teardown": {"duration": 0.0002423750120215118, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_error_messages_do_not_leak", "lineno": 82, "outcome": "passed", "keywords": ["test_error_messages_do_not_leak", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.001354332998744212, "outcome": "passed"}, "call": {"duration": 0.0003785419976338744, "outcome": "passed"}, "teardown": {"duration": 0.0001601249969098717, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_sql_injection_defense", "lineno": 88, "outcome": "passed", "keywords": ["test_sql_injection_defense", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0011677919974317774, "outcome": "passed"}, "call": {"duration": 0.16365495799982455, "outcome": "passed"}, "teardown": {"duration": 0.00019608400180004537, "outcome": "passed"}}, {"nodeid": "tests/test_auth_api.py::test_dependencies_are_minimal_and_no_debug_headers", "lineno": 94, "outcome": "passed", "keywords": ["test_dependencies_are_minimal_and_no_debug_headers", "test_auth_api.py", "tests", "quote-builder-llm-benchmark", ""], "setup": {"duration": 0.0014292910054791719, "outcome": "passed"}, "call": {"duration": 0.16376337500696536, "outcome": "passed"}, "teardown": {"duration": 0.00027379200037103146, "outcome": "passed"}}]}